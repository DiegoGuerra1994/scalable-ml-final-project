{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df085949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import string\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "train_df = pd.read_csv(\"data/train.csv\")\n",
    "test_df = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "206c2f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup the strings so we only get important words\n",
    "\n",
    "#Remove any urls\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "#Remove any extra html\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "#Remove any emojis\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "#Remove puncations and hashtags\n",
    "def remove_punct(text):\n",
    "    table=str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "def clean_tweet(text):\n",
    "    text = remove_url(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_emoji(text)\n",
    "    text = remove_punct(text)\n",
    "    return text\n",
    "\n",
    "#Only apply this to train_df\n",
    "train_df['text'] = train_df['text'].apply(lambda x : clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5da9f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert the text into vectors\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_df['text'], train_df['target'], test_size=0.3, random_state=42)\n",
    "\n",
    "#After splitting into train and test, tokenize\n",
    "x_train_vectors = vectorizer.fit_transform(x_train)\n",
    "x_test_vectors = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09ac6418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+---------------------------------+\n",
      "|          classifier          | train_test_split accuracy score |\n",
      "+------------------------------+---------------------------------+\n",
      "|        knn_classifier        |        0.6711908931698775       |\n",
      "|   decision_tree_classifier   |        0.7329246935201401       |\n",
      "|     logistic_regression      |        0.8064798598949212       |\n",
      "|  multinomial_nb_classifier   |        0.8056042031523643       |\n",
      "|   bernoulli_nb_classifier    |        0.8112959719789843       |\n",
      "|        sgd_classifier        |        0.7837127845884413       |\n",
      "|   random_forest_classifier   |        0.7915936952714536       |\n",
      "| gradient_boosting_classifier |        0.7324868651488616       |\n",
      "+------------------------------+---------------------------------+\n"
     ]
    }
   ],
   "source": [
    "clf_KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_DTC = DecisionTreeClassifier()\n",
    "clf_LOG = LogisticRegression()\n",
    "clf_MNB = MultinomialNB()\n",
    "clf_BNB = BernoulliNB()\n",
    "clf_SGD = SGDClassifier()\n",
    "clf_RFC = RandomForestClassifier()\n",
    "clf_GBC = GradientBoostingClassifier()\n",
    "\n",
    "classifiers = {\n",
    "    \"knn_classifier\": clf_KNN,\n",
    "    \"decision_tree_classifier\": clf_DTC,\n",
    "    \"logistic_regression\": clf_LOG,\n",
    "    \"multinomial_nb_classifier\": clf_MNB,\n",
    "    \"bernoulli_nb_classifier\": clf_BNB,\n",
    "    \"sgd_classifier\": clf_SGD,\n",
    "    \"random_forest_classifier\": clf_RFC,\n",
    "    \"gradient_boosting_classifier\": clf_GBC\n",
    "}\n",
    "\n",
    "table = [[\"classifier\", \"train_test_split accuracy score\"]]\n",
    "\n",
    "for name, clf in classifiers.items(): \n",
    "    clf.fit(x_train_vectors, y_train)\n",
    "    y_predicted = clf.predict(x_test_vectors)\n",
    "    accuracy = accuracy_score(y_test, y_predicted)\n",
    "    table.append([name, accuracy])\n",
    "    \n",
    "tab = PrettyTable(table[0])\n",
    "tab.add_rows(table[1:])\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "903f7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain with full training dataset\n",
    "\n",
    "def generate_submission_file(clf_name, clf):\n",
    "    filename = \"submissions/\" + clf_name + \"_submission.csv\"\n",
    "    f = open(filename, \"w\")\n",
    "    f.write(\"id,target\\n\")\n",
    "    for i in range (len(y_predicted)):\n",
    "        index = test_df['id'][i]\n",
    "        f.write(str(index) + \",\" + str(y_predicted[i]) + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "x_train = train_df['text'].apply(lambda x : clean_tweet(x))\n",
    "y_train = train_df['target']\n",
    "x_test = test_df['text'].apply(lambda x : clean_tweet(x))\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_vectors = vectorizer.fit_transform(x_train)\n",
    "x_test_vectors = vectorizer.transform(x_test)\n",
    "\n",
    "# print(x_train_vectors)\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=5)\n",
    "clf_DTC = DecisionTreeClassifier()\n",
    "clf_LOG = LogisticRegression(max_iter=400)\n",
    "clf_MNB = MultinomialNB()\n",
    "clf_BNB = BernoulliNB()\n",
    "clf_SGD = SGDClassifier()\n",
    "clf_RFC = RandomForestClassifier()\n",
    "clf_GBC = GradientBoostingClassifier()\n",
    "\n",
    "classifiers = {\n",
    "    \"knn_classifier\": clf_KNN,\n",
    "    \"decision_tree_classifier\": clf_DTC,\n",
    "    \"logistic_regression\": clf_LOG,\n",
    "    \"multinomial_nb_classifier\": clf_MNB,\n",
    "    \"bernoulli_nb_classifier\": clf_BNB,\n",
    "    \"sgd_classifier\": clf_SGD,\n",
    "    \"random_forest_classifier\": clf_RFC,\n",
    "    \"gradient_boosting_classifier\": clf_GBC\n",
    "}\n",
    "\n",
    "for name, clf in classifiers.items(): \n",
    "    clf.fit(x_train_vectors, y_train)\n",
    "    y_predicted = clf.predict(x_test_vectors)\n",
    "    generate_submission_file(name, clf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
